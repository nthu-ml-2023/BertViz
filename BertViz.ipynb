{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mg8cmx6PJbt"
      },
      "outputs": [],
      "source": [
        "# Install related tools\n",
        "%pip install bertviz jupyterlab ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOfPS6uiPX9f"
      },
      "outputs": [],
      "source": [
        "# Import related packets and def function\n",
        "from transformers import BertModel\n",
        "from bertviz import head_view, model_view\n",
        "from bertviz.neuron_view import show\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))\n",
        "clear_output()\n",
        "\n",
        "def pred_sentence(model, sentence, tokenizer):\n",
        "  inputs = tokenizer.encode_plus(sentence, return_tensors='pt', add_special_tokens=True)\n",
        "  model = model.to(device)\n",
        "  inputs = inputs.to(device)\n",
        "  with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  probabilities = softmax(logits, dim=1).squeeze().tolist()\n",
        "\n",
        "  print(\"Predicted Probabilities:\")\n",
        "  for class_idx, prob in enumerate(probabilities):\n",
        "      print(f\"Class {class_idx}: {prob:.4f}\")\n",
        "\n",
        "def get_viz(model, sentence, viz_tokenizer):\n",
        "  inputs = viz_tokenizer.encode_plus(sentence, return_tensors='pt', add_special_tokens=True)\n",
        "  token_type_ids = inputs['token_type_ids']\n",
        "  input_ids = inputs['input_ids']\n",
        "  viz_model  = BertModel.from_pretrained(PRETRAINED_MODEL_NAME, output_attentions=True, state_dict=model.state_dict())\n",
        "  attention = viz_model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "  input_id_list = input_ids[0].tolist()\n",
        "  tokens = viz_tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "  call_html()\n",
        "  head_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H963iELVP6AW"
      },
      "outputs": [],
      "source": [
        "# Load model and device setting\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "num_classes = 2\n",
        "loaded_model.config.num_labels = num_classes\n",
        "loaded_model.classifier = torch.nn.Linear(loaded_model.config.hidden_size, num_classes)\n",
        "checkpoint = torch.load('fine_tuned_bert_model.pth', map_location=device)\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_tokenizer = checkpoint['tokenizer']\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = loaded_model.to(device)\n",
        "loaded_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCpUlQrGQafQ"
      },
      "outputs": [],
      "source": [
        "# For the input sentence, output it's predition and attention.\n",
        "input_sentence = \"你是邪惡和超級棒且善良的人\"\n",
        "pred_sentence(loaded_model, input_sentence, loaded_tokenizer)\n",
        "get_viz(loaded_model, input_sentence, loaded_tokenizer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
